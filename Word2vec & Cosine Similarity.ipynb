{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Downloading gensim-4.3.3-cp38-cp38-win_amd64.whl (24.0 MB)\n",
      "Requirement already satisfied: numpy<2.0,>=1.18.5 in c:\\users\\chima\\anaconda3\\lib\\site-packages (from gensim) (1.24.4)\n",
      "Collecting scipy<1.14.0,>=1.7.0\n",
      "  Downloading scipy-1.10.1-cp38-cp38-win_amd64.whl (42.2 MB)\n",
      "Collecting smart-open>=1.8.1\n",
      "  Downloading smart_open-7.1.0-py3-none-any.whl (61 kB)\n",
      "Requirement already satisfied: wrapt in c:\\users\\chima\\anaconda3\\lib\\site-packages (from smart-open>=1.8.1->gensim) (1.11.2)\n",
      "Installing collected packages: scipy, smart-open, gensim\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.5.2\n",
      "    Uninstalling scipy-1.5.2:\n",
      "      Successfully uninstalled scipy-1.5.2\n",
      "Successfully installed gensim-4.3.3 scipy-1.10.1 smart-open-7.1.0\n",
      "Collecting python-Levenshtein\n",
      "  Downloading python_Levenshtein-0.25.1-py3-none-any.whl (9.4 kB)\n",
      "Collecting Levenshtein==0.25.1\n",
      "  Downloading Levenshtein-0.25.1-cp38-cp38-win_amd64.whl (98 kB)\n",
      "Collecting rapidfuzz<4.0.0,>=3.8.0\n",
      "  Downloading rapidfuzz-3.9.7-cp38-cp38-win_amd64.whl (1.7 MB)\n",
      "Installing collected packages: rapidfuzz, Levenshtein, python-Levenshtein\n",
      "Successfully installed Levenshtein-0.25.1 python-Levenshtein-0.25.1 rapidfuzz-3.9.7\n"
     ]
    }
   ],
   "source": [
    "#!pip install gensim\n",
    "#!pip install python-Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kagglehub\n",
      "  Downloading kagglehub-0.2.9-py3-none-any.whl (39 kB)\n",
      "Note: you may need to restart the kernel to use updated packages.Requirement already satisfied: tqdm in c:\\users\\chima\\anaconda3\\lib\\site-packages (from kagglehub) (4.67.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\chima\\anaconda3\\lib\\site-packages (from kagglehub) (20.4)\n",
      "Requirement already satisfied: requests in c:\\users\\chima\\anaconda3\\lib\\site-packages (from kagglehub) (2.24.0)\n",
      "Requirement already satisfied: colorama; platform_system == \"Windows\" in c:\\users\\chima\\anaconda3\\lib\\site-packages (from tqdm->kagglehub) (0.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\chima\\anaconda3\\lib\\site-packages (from packaging->kagglehub) (2.4.7)\n",
      "Requirement already satisfied: six in c:\\users\\chima\\anaconda3\\lib\\site-packages (from packaging->kagglehub) (1.15.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\chima\\anaconda3\\lib\\site-packages (from requests->kagglehub) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\chima\\anaconda3\\lib\\site-packages (from requests->kagglehub) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\chima\\anaconda3\\lib\\site-packages (from requests->kagglehub) (1.25.11)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\chima\\anaconda3\\lib\\site-packages (from requests->kagglehub) (3.0.4)\n",
      "Installing collected packages: kagglehub\n",
      "Successfully installed kagglehub-0.2.9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip install kagglehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import pandas as pd\n",
    "import kagglehub\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version, please consider updating (latest version: 0.3.6)\n",
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/arhamrumi/amazon-product-reviews?dataset_version_number=1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 115M/115M [00:01<00:00, 66.3MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting model files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\chima\\.cache\\kagglehub\\datasets\\arhamrumi\\amazon-product-reviews\\versions\\1\n"
     ]
    }
   ],
   "source": [
    "#Getting Amazon Product Review Data from the Kaggle\n",
    "\n",
    "\n",
    "\n",
    "# Download the dataset\n",
    "path = kagglehub.dataset_download(\"arhamrumi/amazon-product-reviews\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>ADT0SRK1MGOEU</td>\n",
       "      <td>Twoapennything</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1342051200</td>\n",
       "      <td>Nice Taffy</td>\n",
       "      <td>I got a wild hair for taffy and ordered this f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1SP2KVKFXXRU1</td>\n",
       "      <td>David C. Sullivan</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1340150400</td>\n",
       "      <td>Great!  Just as good as the expensive brands!</td>\n",
       "      <td>This saltwater taffy had great flavors and was...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A3JRGQVEQN31IQ</td>\n",
       "      <td>Pamela G. Williams</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1336003200</td>\n",
       "      <td>Wonderful, tasty taffy</td>\n",
       "      <td>This taffy is so good.  It is very soft and ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>B000E7L2R4</td>\n",
       "      <td>A1MZYO9TZK0BBI</td>\n",
       "      <td>R. James</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1322006400</td>\n",
       "      <td>Yay Barley</td>\n",
       "      <td>Right now I'm mostly just sprouting this so my...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>B00171APVA</td>\n",
       "      <td>A21BT40VZCCYT4</td>\n",
       "      <td>Carol A. Reed</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1351209600</td>\n",
       "      <td>Healthy Dog Food</td>\n",
       "      <td>This is a very healthy dog food. Good for thei...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   ProductId          UserId                      ProfileName  \\\n",
       "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "5   6  B006K2ZZ7K   ADT0SRK1MGOEU                   Twoapennything   \n",
       "6   7  B006K2ZZ7K  A1SP2KVKFXXRU1                David C. Sullivan   \n",
       "7   8  B006K2ZZ7K  A3JRGQVEQN31IQ               Pamela G. Williams   \n",
       "8   9  B000E7L2R4  A1MZYO9TZK0BBI                         R. James   \n",
       "9  10  B00171APVA  A21BT40VZCCYT4                    Carol A. Reed   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                     1                       1      5  1303862400   \n",
       "1                     0                       0      1  1346976000   \n",
       "2                     1                       1      4  1219017600   \n",
       "3                     3                       3      2  1307923200   \n",
       "4                     0                       0      5  1350777600   \n",
       "5                     0                       0      4  1342051200   \n",
       "6                     0                       0      5  1340150400   \n",
       "7                     0                       0      5  1336003200   \n",
       "8                     1                       1      5  1322006400   \n",
       "9                     0                       0      5  1351209600   \n",
       "\n",
       "                                         Summary  \\\n",
       "0                          Good Quality Dog Food   \n",
       "1                              Not as Advertised   \n",
       "2                          \"Delight\" says it all   \n",
       "3                                 Cough Medicine   \n",
       "4                                    Great taffy   \n",
       "5                                     Nice Taffy   \n",
       "6  Great!  Just as good as the expensive brands!   \n",
       "7                         Wonderful, tasty taffy   \n",
       "8                                     Yay Barley   \n",
       "9                               Healthy Dog Food   \n",
       "\n",
       "                                                Text  \n",
       "0  I have bought several of the Vitality canned d...  \n",
       "1  Product arrived labeled as Jumbo Salted Peanut...  \n",
       "2  This is a confection that has been around a fe...  \n",
       "3  If you are looking for the secret ingredient i...  \n",
       "4  Great taffy at a great price.  There was a wid...  \n",
       "5  I got a wild hair for taffy and ordered this f...  \n",
       "6  This saltwater taffy had great flavors and was...  \n",
       "7  This taffy is so good.  It is very soft and ch...  \n",
       "8  Right now I'm mostly just sprouting this so my...  \n",
       "9  This is a very healthy dog food. Good for thei...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_local = r'C:\\Users\\chima\\.cache\\kagglehub\\datasets\\arhamrumi\\amazon-product-reviews\\versions\\1\\Reviews.csv' \n",
    "df = pd.read_csv(path_local)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's Preprocess the text present here \n",
    "Text = df.Text.apply(gensim.utils.simple_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         [have, bought, several, of, the, vitality, can...\n",
       "1         [product, arrived, labeled, as, jumbo, salted,...\n",
       "2         [this, is, confection, that, has, been, around...\n",
       "3         [if, you, are, looking, for, the, secret, ingr...\n",
       "4         [great, taffy, at, great, price, there, was, w...\n",
       "                                ...                        \n",
       "568449    [great, for, sesame, chicken, this, is, good, ...\n",
       "568450    [disappointed, with, the, flavor, the, chocola...\n",
       "568451    [these, stars, are, small, so, you, can, give,...\n",
       "568452    [these, are, the, best, treats, for, training,...\n",
       "568453    [am, very, satisfied, product, is, as, adverti...\n",
       "Name: Text, Length: 568454, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Text #This is the input to gensim model, a list of words. Sequence matters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialization\n",
    "\n",
    "model = gensim.models.Word2Vec(\n",
    "    window=10,\n",
    "    min_count=2,\n",
    "    workers=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to build vocabulary: 13.58 seconds\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time() #Start Time\n",
    "model.build_vocab(Text, progress_per=1000)\n",
    "t1 = time.time() #End Time\n",
    "print(f\"Time to build vocabulary: {t1 - t0:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to build Model: 101.14 seconds\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time() #Start Time\n",
    "model.train(Text, total_examples=model.corpus_count, epochs=model.epochs)\n",
    "t1 = time.time() #End Time\n",
    "print(f\"Time to build Model: {t1 - t0:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save this model rather than training it again and agian\n",
    "model.save(\"./word2vec-amz-reviews-short.model\") #~ 54MB model size. Wonder if we can optimize the size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: adore, Similarity: 0.7567824125289917\n",
      "Word: loves, Similarity: 0.6776376962661743\n",
      "Word: enjoy, Similarity: 0.6320818066596985\n",
      "Word: loved, Similarity: 0.6234462857246399\n",
      "Word: enjoys, Similarity: 0.5778928995132446\n",
      "Word: likes, Similarity: 0.5306829810142517\n",
      "Word: loving, Similarity: 0.5296709537506104\n",
      "Word: loooove, Similarity: 0.522752583026886\n",
      "Word: fantastic, Similarity: 0.5199699401855469\n",
      "Word: adores, Similarity: 0.5120050311088562\n",
      "Word: yummy, Similarity: 0.5043520331382751\n",
      "Word: fabulous, Similarity: 0.503262996673584\n",
      "Word: enjoyed, Similarity: 0.49724164605140686\n",
      "Word: awesome, Similarity: 0.4938930571079254\n",
      "Word: like, Similarity: 0.49128180742263794\n",
      "Word: delicious, Similarity: 0.48785728216171265\n",
      "Word: terrific, Similarity: 0.4861878454685211\n",
      "Word: wonderful, Similarity: 0.47923609614372253\n",
      "Word: amazing, Similarity: 0.47516587376594543\n",
      "Word: liked, Similarity: 0.4626755714416504\n"
     ]
    }
   ],
   "source": [
    "# Find words similar to a given word\n",
    "similar_words = model.wv.most_similar(\"love\", topn=20)  # Top 10 most similar words\n",
    "for word, similarity in similar_words:\n",
    "    print(f\"Word: {word}, Similarity: {similarity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time() #Start Time\n",
    "\n",
    "#Find Words with highest Cosine Similarity\n",
    "# Get all vocabulary words\n",
    "words = list(model.wv.index_to_key)\n",
    "\n",
    "# Find the most similar word pairs with cosine similarity > threshold\n",
    "threshold = 0.8\n",
    "similar_pairs = []\n",
    "for i, word1 in enumerate(words):\n",
    "    for word2 in words[i+1:]:  # Avoid duplicates (similarity(a, b) == similarity(b, a))\n",
    "        similarity = model.wv.similarity(word1, word2)\n",
    "        if similarity > threshold:\n",
    "            similar_pairs.append((word1, word2, similarity))\n",
    "\n",
    "# Sort by similarity\n",
    "similar_pairs = sorted(similar_pairs, key=lambda x: -x[2])\n",
    "\n",
    "# Print results\n",
    "for word1, word2, similarity in similar_pairs[:20]:  # Show top 20\n",
    "    print(f\"Word1: {word1}, Word2: {word2}, Similarity: {similarity}\")\n",
    "    \n",
    "t1 = time.time() #End Time\n",
    "print(f\"Time to build Model: {t1 - t0:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
